{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: get the subtitles/caption of Dr. Lisa Feldman Barrett's talk\n",
    "> Lisa Feldman Barrett: Emotion inside out <br> https://www.youtube.com/watch?v=h7Mtwds0wW4\n",
    "\n",
    "Stages:\n",
    "1. open transcript from Youtube and copy paste into new Excel sheet and save on Desktop\n",
    "2. be sure to add on the top row the column header (e.g. 'words') as it's so much easier than doing it here\n",
    "3. make sure the directory is set to Desktop\n",
    "4. using pandas, read excel into dataframe\n",
    "5. concatenate all the words into one string (note: omfg this took me so long, but only after 'df.COLUMN_HEADER.' can you 'str.cat.')\n",
    "6. copy paste to word for profit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so I'm gonna start off by talking about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cartoons who here likes cartoons I know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right cartoon chemistry is about mixing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colorful liquids and watching them blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>up and cartoon physics is about running</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     words\n",
       "0  so I'm gonna start off by talking about\n",
       "1  cartoons who here likes cartoons I know\n",
       "2  right cartoon chemistry is about mixing\n",
       "3  colorful liquids and watching them blow\n",
       "4  up and cartoon physics is about running"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Workbook2.xlsx',header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"so I'm gonna start off by talking about cartoons who here likes cartoons I know right cartoon chemistry is about mixing colorful liquids and watching them blow up and cartoon physics is about running off a cliff and not falling until you look down and now the science of emotion has its own cartoons this is the Pixar movie inside out these are little characters in your brain one for joy sadness disgust fear and anger and this was filmed in the United States so joy is the leader now we know that chemistry is about more than blowing things up and gravity unfortunately really does exist in the real world no one would expect to learn anything about chemistry and physics from watching cartoons but when it comes to emotion the characters that were inspired the characters in inside out were inspired by an actual scientific theory this is called the classical view under if mentioned the classical view of emotion for those of you in the know it includes basic emotion theory in some versions of appraisal Theory an animation is the perfect vehicle for characterizing the classical view because it's steeped in essentialism essentialism for those of you who don't remember is the belief that a category of instances that all have the same name like anger share some physical fingerprint some facial expression or some autonomic pattern of nervous system changes and a deep underlying causal mechanism like a neural circuit so I want to start off by examining three examples of essentialism in the classical view of emotion and then call them into question or as I prefer to say destroy them with the data the classical view stipulates that emotions are displayed on the face with expressions that we recognize this is the first example of essentialism so people are supposed to smile when they're happy they're supposed to frown when they're sad they're supposed to scowl when they're angry and everyone around the world is supposed to be able to recognize smiles and frowns and scowls as expressions of emotion now I could present we could spend two hours talking about the data that don't correspond to this hypothesis but I'm just gonna show you one meta analysis to dispel this essentials claim this is a meta-analysis of 37 studies where scientists evoked emotion in participants and then measured their facial movements either using fax coding facial action unit coding or using facial EMG that is the electrical signals of the facial movements themselves some studies report a correlation between the stipulated expression the stipulated the believed expression and another measure of emotion those are depicted in blue bars some studies just examined the proportion of people in an emotion condition who showed that expression so how many what is the proportion people in a study of anger who actually made a scowling face and on the Left y-axis what you see is the effect sizes so what you can see here is that in no study of emotion is any facial expression that's been proposed as the expression of emotion in no study I mean in no category is that expression dominant so people don't routinely scowl when they're angry they sometimes skele when they're angry but they actually make many different sets of facial actions when they're angry and sometimes they scowl when they're not angry and actually this is true for every stipulated expression that we believe to be diagnostic of emotion so what this tells us is that it's really not a good idea to make a reverse inference that when you see someone scowling it necessarily means that they're angry and actually these data data like these if I showed you a meta-analysis of studies of children making facial movements while they're expressing emotion of infant's of people who are born congenitally deaf or blind the results would pretty much look like this the punchline here ok is that many different facial movements are observed during instances of the same category so there's a many to one mapping which in biology is called degenerate see so here's an example when people look at this face and I asked you know how does this person feel they only should say oh she's expressing grief she's in pain she's fatigued maybe she's really sad this is actually my daughter Sophia from last year when we were at the chocolate Museum in Cologne Germany and I can assure you what she's experiencing is a profound sense of pleasure and this little sweetie is also experiencing a profound sense of pleasure and what I want you to do is just focus in on his eyebrows if you just looked at his eyes and his eyebrows you actually what he's making is the kind of movement that looks like it's part of a scowl so people move their faces in many different ways during the same emotion studies also observe that a single set of facial movements can express many different emotion categories so how does this person feel when I ask people they say oh she's in terror she's in pain but actually this is Serena Williams from now a number of years ago when she beat her sister Venus at the US Open because like what is better than beating your sister right but without context we see her face as communicating terror because this face is actually made in terror so different expressions different facial movements express the same emotion but the same set of facial movements can also express different emotions and so the punchline here is that a face doesn't speak for its when it comes to emotion so what about these expressions well it turns out that historically speaking these expressions were not discovered by observing people express emotion in real life in fact they were stipulated by a handful of scientists and then adopted as the universal truth they actually meet the criteria for stereotypes and so if you think about that for a minute what you realize is that in the science of emotion for almost a hundred years now we've been studying expressive stereotypes so we have a nice robust science of stereotypes how people actually express emotion however is a completely different and much more variable in situated man matter here's the second example of essentialism that emotions have bodily fingerprints so the hypothesis is that when you're angry your body takes on the same set of physical changes maybe blood pressure goes up maybe you flush maybe your heart rate goes up and so on and so forth so again I'm going to show you a meta-analysis this is analysis that is we just are is now impressed at psychological bulletin this is 233 papers including involving over 20,000 subjects these are non clinical subjects on the x-axis I'm going to depict the effect size and on the y-axis I'm going to depict the type of autonomic measure so this again these are studies where subjects were exposed to a stimulus that would induce emotion and then their autonomic nervous system changes were measured here are the effect sizes for neutral induction the shape represents the average effect size the size of the shape represents the number of studies available for analysis so a larger shape means that there were more studies available and the lines represent the variability it's the confidence interval 95% confidence interval now if indeed the classical view is correct then each emotion category should have its own profile of autonomic changes and we should see very little overlap in the effect sizes so here are the effect sizes for anger for fear for disgust for sadness for happiness so we see that there are no autonomic nervous system changes that are unique to any emotion category instead there's tremendous overlap in the distributions of autonomic features and that's true whether we do a univariate analysis like I'm showing you here or whether you do pattern classification right so once again we find variation is the norm in anger your blood pressure can go up it can go down it can stay the same it all depends on what your brain is preparing your body to do and in fact physiologists have known this for over 50 years that your physio that physiological changes in your body are linked to action right not to emotion and if it's the case that sometimes in anger you run and sometimes you freeze and sometimes you laugh in the face of anger and sometimes you strike out in anger then the physiology will follow along in within be highly variable which is what we see the third example of essentialism is the idea that there is a dedicated emotion circuit in the brain for each emotion so you know we feel emotions as you know if they happen to us right like some little bomb went off in our head and they take over our behavior and they cause us to do and say things that we sometimes wish we didn't and this makes us believe that emotions are baked into some you know inner beast in some ancient part of our brains but experiences of emotion don't reveal the brains inner workings any more than watching the Sun move across the horizon reveals the structure of the solar system so I'm going to show you again a meta-analysis this is a meta-analysis of brain imaging studies hundreds of studies this is from my lab in conjunction with tor weygers lab we use pattern classification to diagnose the specific emotion category that was being cultivated in neuroimaging studies so we used to leave one out method where what we did is we took all of the studies except one trained a Bayesian classifier using a spatial point process model which is a multivariate modeling approach and we developed a classifier to classify the emotion category of the one study that we left out we had one math and we would classify it and then we just did that again and again and again iteratively throughout the whole meta analytic database and this gave us a set of patterns that we were able to use to successfully diagnose the emotion that was being cultivated in a particular study based on the average contrast map the average pattern of activity for that study now if you look at this and you say aha well this is evidence that the classical view of emotion is right because here we have the neural signature or fingerprint of each emotion then you would be in good company because that's how these patterns are usually interpreted in the literature but and I have to tell you what I'm about to say maybe it will make sense to you I hope it will but um my colleagues who are statisticians and engineers look at this and say well nobody nobody would really believe that you know because everybody knows that these are not brain states there are statistical abstractions they're just statistical summaries so believing that that is the brain state for anger or the green pattern is the brain state for or the green pattern is the brain say for disgust is like believing that if on average there are three point one three people in an American family that every family has three point one three people in it as far as I know no family that I know of has three point one three people in it that was a joke and thank you for that laughs that was good so here's how pattern classification works if we have a a map of activity and that map is statistically closer to the red map than it is to any of the other maps then it will be classified as anger but it can be diagnosed we can diagnose studies with a hundred percent accuracy and the study maps don't have to have a single activation in common with that red map right so there can be nothing physically in common between a study and the pattern and you can still diagnose the study as being anger that's how pattern classification works patterns are statistical abstractions they aren't brain states and this helps us understand why pattern classification studies produce different patterns in different studies because the classifiers are not brain States there are statistical abstractions just like in a distribution you have a mean and a variance and the mean itself is a statistical abstraction so this again is example that the brain states for any category of emotion are highly variable even though you can summarize them with a single abstract prototype now just in case you're tempted to dismiss the brain imaging evidence as irrelevant because you know fMRI is is a spatially course here's an one just one example from a lesion study this is a study of monozygotic twins who have our back swipes disease which it calcifies the amygdala which you can see in the two images these are axial horizontal slices of the brain there's a two sister and their calcified amygdalas are outlined in blue for sister BG and in green for sister am so they have identical these sisters have identical genes they grew up in in similar environments they currently live in similar circumstances they have both have high school diplomas and they're of average IQ but BG has fear related deficits that are similar to the patient famous patient SM whereas AM does not she experiences fear and perceives fear in a normal fashion and even SM the famous patient SM you know who also has this disease and has a calcified amygdala and is famously known for not recognizing the wide eyed sort of stereotype for fear can perceive an experienced fear if you look really closely there's a beautiful chapter in a book called living without an amygdala by Justin Weinstein and he talks about how she can perceive fear embodies and invoices this is both observed in the lab and in her real life when she tries to call the police to help her friends who are in danger she can even perceive fear in posed faces facial the facial stereotypes when her eyes are directed to the when her gaze is directed to the eyes of the face actually SM is also capable of what is typically called fear learning in the world right so in the lab she has a hard time learning that a neutral object predicts threat but in the real world she learns this perfectly as evidenced by the fact that she when she experiences pain in the dentist's office she doesn't want to go back to that dentist she avoids the dentist and she also is averse to breaking the law for fear of getting in trouble she doesn't use the word fear instead she uses the word worried but basically she along with the twins here are evidence that it's possible for a brain to make fear without an amygdala and this means that there must be multiple ways that a brain can make an instance of fear now at this point you might be thinking okay well no one really believes that every instance of the same emotion category is identical right in its facial expression or in its bodily change or in its brain state and this is true but classical views tend to explain variation first of all they assume that there isn't that much variation and they assume the variation is sort of epiphenomena to the emotion itself so an issue here in the science of emotion is how much variation is there within a category how much similarity is there across categories and is this variation and similarity intrinsic to the nature of emotion or is it something outside of an emotion so here's a theoretical space that we can use to depict these differences basic emotion theory in its original form and discrete emotion theory for those developmental lists in the audience make the assumption that on the surface surface features that you can observe like facial movements and autonomic changes are supposed to be highly similar for the instances of the same category and the assumption is that there's a stable underlying mechanism that is enduring and immutable that causes these changes that's the theory all right and the theory says that if we observe anything other than this stability that the variability is due to causes that are not due to the emotion itself like regular emotion regulation or maybe you know the induction wasn't strong enough and so on and so forth the revised version of basic emotion theory allows for more variability in surface features but still assumes that there's this underlying immutable cause there's an anger mechanism there's a fear mechanism there's a sadness mechanism and they're all different other theories start to relax this view so Shearer's component process model functional theory for example like Ralph Adolf's theory descriptive appraisal theories like Gerry klore and Andrew or Tony's theory & korek theory Jim Russell's theory all assume that that there's a reasonable amount of similarity within a category but also some similarity across categories right so the red zone here really refers to classical categories that have necessary and sufficient features the yellow zone here assumes that emotion categories are like prototype categories but there's another class of theoretical approaches mine included which assume that the physical changes that occur in emotion in a particular category are highly variable and very situated and the mechanism that holds them together is not a deep immutable like unchanging cause that in fact what the brain is doing is it's flexibly collecting instances together that look different that are measurably different but because they're serving the same function in a given situation and so what I'm gonna do for the rest of the time today is explain to you a little bit about what this perspective looks like in the science of emotion what are the kinds of questions that we ask when we assume that emotion categories are conceptual categories that conceptually we're linking together a bunch of instances because they all serve a similar purpose in a particular situation I mean basically what this approach leads us type aa the size is that emotions are not built into your brain at birth they're just built as you need them on the fly situated by highly constrained by the situation and to give you an intuition for what this looks like I'm going to show you a visual illusion so right now billions of neurons in your brain are try to make sense of these blobs so that you see something other than these blobs and your brain is sort of searching through a lifetime of past experiences that can be kind of recon jerd in its wiring issuing thousands of guesses at once weighing probabilities trying to answer the question what is this like from my past experience not what is it but how it what is this like what is this similar to based on things I've seen before and it's all happening in the blink of an eye under the awareness even me telling you about it doesn't allow you to kind of access consciously how your brain is doing it now most people still at this point we'll see blobs and if that's the case it's because your brain hasn't found a good match from past experience and I call this and other philosophers call this experiential blindness and so now I'm going to cure you of your experiential blindness are you ready to be cured yeah well let's do that again okay so at this point who here sees a B now yeah so what's happening under the hood well now when your brain searches through your past experiences you're you have new knowledge there from the color photograph and that knowledge changes how you experience these blobs so your brain is constructing the image of a B even when there's no B present your brain to do this is changing the firing of its own sensory neurons without incoming sensory input linking the blobs into the shape of a B making you see lines that are not physically present right so even though there are no lines and therefore no sensory input at those junctures you're still constructing the image of a B so you are in a manner of speaking hallucinating not the kind of scary I better get myself to the hospital kind of hallucination and it's always so much fun to say that in front of psychiatry people in psychiatry um but the everyday kind of my built is everyday sort of like my brain is built to work like this hallucination scientists have fancy names for this kind of hallucination we call it simulation or recall at perceptual inference or we call it running an internal model of the world or we call it something simple like memory so who here's ever had like a song playing in their head that they can't get rid of right yeah exactly this audio hallucination is also a function of simulation or memory or you know your internal model understanding how the brain creates an internal model by reconstituting past experiences for the use in the present is the secret to understanding how the brain constructs experiences and perceptions of emotion and obviously not just emotion actually every experience you ever have but today we're just gonna talk about emotion nothing too ambitious for you know a Tuesday afternoon so here's an example of how internal model work in the brain what we did is we asked people to create an internal model of events in their minds just by listening to scenarios that were written and so here what you're looking at are increases in bold signal related to neural activity in the epoch in the part of the trial where subjects are no longer listening to the scenario so they've just been asked to embody to deeply imagine the scenario as if it were happening to them subjects raided these experiences as very very high on subjective realism meaning they felt real and this is what the brain activity looks like or the well the bold activity looks like which you know corresponds to neural activity in some way despite the fact that subjects are lying very still in the scanner we see an increase in activity in somatosensory cortex and in primary motor cortex and actually supplementary motor cortex as well and premotor somewhat despite the fact that their eyes are closed we see an increase in activity in early visual cortex we also see activity in a change in activity in primary interceptive cortex meaning that the brain is modeling the internal sensory changes from the body's inner systems the autumn the autonomic nervous system the immune system the neuro endocrine system and importantly we also see changes in activity in the thalamus hypothalamus and in the subcortical nuclei that regulate the body's internal systems so this is the P the periaqueductal gray or PG pair brachial nucleus and reaching down all the way into the nucleus of solitarius tract so merely by imagining right we see an orchestra of neural changes in the brain now the internal model that your brain runs is not just for imagination it's the basis of your brain actually works and this I think is one of the most important discoveries in the past decade because it leads to the unintuitive but revolutionary insight that the brain is not reactive its predictive what we see what we hear what we taste and what we feel are predictions that are generated as simulations by our internal model which are then confirmed or tweaked by sensory input from the periphery so the idea that the brain works by stimulus and response you know like a clever experiment is just false this approach now I should say this approach is um it's called predictive coding or Bayesian active inference it's actually the hypotheses that are embodied in this approach have actually been around since the time of Helmholtz or an even before but they're significantly updated and backed up by a tremendous amount of scientific evidence that's rapidly growing as we speak there's evidence from the structure of nervous systems from the neuro anatomical structure of nervous systems there's evidence from the physiology of nervous systems from the electrical processing of nervous systems there's evidence from brain imaging from the in Elect measurement of activity of individual neurons and so on all of which support a predictive coding approach every Xterra septic system sensory system in your body there's evidence that it works by prediction and there's a growing amount of evidence that the motors your motor system works that way as well so to make sense of this I think it's really helpful sort of give you an intuition for it it would be to take the brains perspective for a minute so your brain has to figure out what is going on in the outside world so that it knows how to act to keep you alive and well and this is a really hard task because for your entire life your brain is entombed in a dark silent box called your skull that barely got a Joe laughs okay it your brain is learning what's going on in the world only indirectly by scraps of information that it receives through the sensory channels of your body right the sights and sounds and smells and so on that come through the body sensors and it's it its job is to try to make sense of those sensations to figure out what caused those sensations so that it knows what they mean and knows what to do about them the problem right is that the sensory information is noisy and it's ambiguous and sometimes it's incomplete and any given sensation any flash of light or or sound can have many different causes so how does the brain solve the puzzle it's basically having to make a reverse inference it has to basically guess the causes of sensations only knowing their effects well it has another source of information that it can rely on past experiences that are wired in to your brain and it uses these generatively to create simulations that predict incoming sensory inputs before they arrive to your brain and the really cool thing is that from your brains perspective your body also works this way so there are sensation sensory inputs that are coming from your body from your lungs expanding from your heart pounding from your muscles use of glucose and so on from inflammatory processes from metabolism and so your brain trapped inside your skull is running an internal model of your body in the world that functions like a set of prediction signals so these signals are like you know scientists will sometimes refer to them as Bayesian filters for incoming sensory inputs what you experience even in your body is an example of the remembered present to use Gerald Edelman's term a remembered present that's confirmed or modified by the sensory periphery and this is the default process by which your brain interprets navigates the world when I'm talking to you know audiences who are not scientist and I say you know pinch your hand where do you feel that pinch do you feel it in your hand or do you feel it in your brain you feel it in your brain not in your hand so your emotions are not in your heart right I mean even though we speak like that and even I speak that way right when I'm just being a civilian but it feels right it where it is where do we feel our heart we feel our hearts in our brains so we have this running internal model and the internal model is is modified or tweaked or or confirmed by the data that's coming from the sensory world and that sensory world isn't just x.t receptive is also including our bodies so I'm gonna go through this again as a summary because for people who are not familiar with predictive coding it's a confusing set of claims so I want to make sure that that they're clear in every waking moment of your life your brain is basically functioning like a scientist so you're a scientist even if you didn't know it it predicts what's gonna happen in the next moment in the world and in your body and in fact the majority of your brain activity is devoted to this internal model it's your brain is issuing predictions thousands at a time based on past experience no your brain is the most expensive organ in your body it takes up about 20% of your metabolic budget and between 60 and 80 percent of that metabolic budget is devoted to running this internal model and then your brain checks the model against incoming sensory inputs and when these predictions are correct they automatically become your experience and guide your action this is equivalent to what we would call automatic processing or system 1 processing see the baby finds it just shocking that that's true sometimes predictions are not correct and your brain has to adjust so what does your brain do in such cases well sometimes it tweaks your it will tweak itself it will it will take in the errors the sensory input that it is an error prediction error right so it will learn basically the sensory changes that it didn't predict and that's our fancy name for taking in prediction error we call it learning and that's what allows the brain to adjust its internal model sometimes though the brain won't take in the information it will adjust how it's processing that internal information so for example it might ignore some of that in that at that external information that prediction error it might ignore some information or it might decide to move the body so that it generates the sensations it was expecting either way this is all very effortful and this is what we refer to as system two or controlled processing so automatic and controlled processing system 1 and system 2 are not literal networks in your brain there are different modes of processing of your brain's internal model and this is how air pressure becomes sound how light becomes vision how chemicals in the world become smells and how aches and shivers and other sensations inside your body become affect now thirty years of research shows how the brain accomplishes predictive coding here what I'm showing I'm gonna show you is um comes from Helen Barba's lab she has a theory called the structural model of cortical cortical connections and what she shows is that lamination gradients within the cortex predict information flow across the cortex so what does that mean that means is if you lift the cortical sheet off the brain and you stretch it out like a napkin and you look at it in three in in sort of in cross-section what you see is that the neurons are arrayed in layers and some of parts of cortex have through four layers so they're missing a layer four and layers two and three are not differentiated those are depicted in dark grey they're called a granular cortex some parts of cortex have six layers a very rudimentary layer four and some have of the full sort of six layers that we think of as cortical and so dis granular meaning there's a very rudimentary layer four is in light gray and then in the lightest gray is granular cortex and what Helen's work has shown thirty years of really careful tract tracing studies in many many different mammalian species but mostly in macaques shows that the relative lamination in between two cortical regions determines whether or not the information is prediction or prediction error and so according to this model the the source of your internal model that initiates predictions is are the regions that are a granular and to some extent dis granular so the darkest regions send prediction signals to the lighter regions and you know although to the lightest regions basically and prediction errors flow in the other direction there's another name though that these really dark regions go by and I should say this is not in contention this is not hypothesis this is pretty well backed up by a lot of evidence not just from Helens lab but the idea that that that prediction signals flow in this direction but there's another name for these dark gray regions does anyone know what that name is what a hazard I guess well here I'm going to present them to you in color this is actually I just found this a plot that I had remade of it's a an image of Von Economo cell counts which empirically determined the the lamination gradients in the brain the other name for a granular brain tissue is limbic so I hope you're grasping the irony here for centuries scientists have considered limbic regions to be the home of emotions right the most reactive parts of the brain that are in need of control right so they're supposed to be like your inner beast right that that has to be controlled by your you know prodigious cognitive abilities associated with the cortex but actually as we now know these regions are the source of prediction signals that drive perception and action in your brain not just during emotion but during all mental events from the moment that you are born until the moment that you die your brain is predicting sensory inputs from the world and anticipating how to act on them with limbic cortices now not solely limbic core disease because it turns out the hippocampus which is a limbic area but it's not cortical kin it's really considered a low cortex right in the kind of the center between um subcortical and cortical regions so it's got three layers it is also important for prediction and the cerebellum plays a role and so I'm not saying that the court the limbic cortices are the exclusively important parts that are initiating predictions but they are initiating prediction signals and so we wanted to see the full extent of the systems in the brain that were important for initiating predictions and so we seated all limbic cortical regions in the brain and used an analysis of connectivity analysis on resting-state data which just means subjects were lying still in the scanner and we found a system for prediction consisting of two overlapping networks and I'm not saying that predictions live in this system I'm saying this is where all of the limbic tissue all of the limbic cortical tissue in your brain is actually found in these two networks so this is these are networks are responsible for initiating running the internal model that that are initiating the changes in the internal model that become the predictions that guide your action and create your experience and these two networks for anyone who's familiar with intrinsic networks research on trend networks should be they should be familiar to you one is called the default mode network the other is called the salience network now these networks you know these networks have more aliases than Sherlock Holmes right they get caught people label these networks in line with whatever they're interested in so they have met they go by many many different names but the point is that that these two networks and the places in the brain where they overlap are important they contain all of the a granular limbic tissue in the brain and what's really interesting too is that they also both of them contain the posterior insula which we know from Bud Craig's work and other anatomical work is primary interest optic cortex primary sensory cortex for insi receptive input from the body meaning that this system is not just for important for prediction it's also important for interception and for effect now here are some interesting tidbits about this network first of all these networks have very extensive subcortical projections more than anything that's been previously assumed so what I've done is I've taken the I should say the blobs here refer to connectivity not activity and what I've done is I've taken the connectivity and projected it into the volume of the brain so that you can see the subcortical connectivity so both of these networks and the hubs in which they overlap are connected to the hypothalamus the PA G the pair brachial nucleus and even down to the NTS I'm showing you here this is intrinsic connectivity using brain imaging but all of these pathways have been confirmed in tract tracing studies in macaques so they're hardwired this means that whatever else these networks are doing psychologically speaking they are also regulating the systems of your body so it's not like some parts of your brain regulate your body and other parts of your brain are good for thinking and other parts of your brain are good for feeling it's exactly the same exactly the same networks exactly the same networks now you might want to argue that it's not really the same neurons in those networks but tract tracing studies would suggest otherwise so what are these networks doing well here's just a selection of imaging studies I picked up images for that show an increase in bold response during various tasks for the default mode Network so the default mode network has been implicated in a range of tasks domains everything from perception to cognition to emotion to decision-making and so on processing of concepts and so on and so forth so it's I think it's interesting that in the past what we've done in neurosciences tried to link the function of a particular Network well at first we tried to link functions psychological unctuous to particular regions of the brain then we found out that that didn't work and so people tried to link functions of networks to particular psychological domains and that's also not the case that each network is is a multi process you could call it or you could call it domain general is implicated in a variety of functions this is also true for the salience Network and there are just two images I want to draw your attention to one is at the bottom right in the Christmas colors of red and green this is a meta-analysis that my lab did where we took basically all a bunch almost 6,000 studies the increase in bold response in 6,000 studies and just dumped it into a meta-analysis to see like why are there any hotspots in the brain that are always showing an increase in activity and what we basically get out is a nice tidy image of the salience Network and at the top right is not a brain it's not a functional study it's actually a meta-analysis of 15,000 people who have one of six who've been diagnosed with one of six mental disorders and this is the common atrophy that you see in those disorders and again it's the salience network now physiologist and electrical engineers have argued that the core task of all brains is to regulate an organisms internal milieu by anticipating the needs of the organism the metabolic needs and preparing to satisfy them before they arise if you haven't if you're interested in this kind of material I would recommend that you get this book by Peter sterling that was published in 2015 in MIT by MIT press called principles of neural science an absolutely fantastic I'm treatment of these issues this idea unifies the mind in a way that places metabolism and energy regulation which is more technical name is called allo stasis as well as the sensory consequences of that regulation interception at the core of all mental activity in emotions for sure but also in thinking and perceiving and enacting and deciding so from a biological standpoint does not make sense to divide emotion and cognition in two separate faculties where one regulates the other or insist that behavior is some kind of you know compromise or cooperation between the two the brain constructs predictions in the service of a low stasis and all predictions even those which are subjectively cold where effect you know is in the background of consciousness contain information about interception and some affective tone even if it's really subtle so Alice stasis an interception might be considered properties of the nervous system not specific to particular instances of emotion these networks that I showed you also that are the origins of prediction based on the tract tracing studies and that control the body also control the nuclei in the brainstem that originated the neuromodulators that control attention so the brain regions so what I'm showing you here are again connectivity maps the blobs refer to connectivity not refer to activation and the blobs basically are showing you the cortical regions and some of the subcortical regions that are connect to the the locus coeruleus and so on the these are the bed nuclei that originate neuromodulators in the brain so limbic circuitry isn't just originating predictions and it's not just controlling your body it's also controlling your attention what you pay attention to which makes sense right because actually encoding prediction error is one of the most expensive things your brain can do there are two things that are really expensive metabolically speaking one is moving your body and the other is learning now your brain is not metabolically frivolous it's not going to expend the energy to learn something unless it's predicting that that information is going to be useful for future episodes of Alice stasis so this is what I always tell my husband you know after I bought yet another black sweater or a pair of shoes that I really don't need no my brain is frugal right I am only encoding information that I absolutely need for Alice stasis and these shoes were part of that yep these ideas can help us derive specific computational hypotheses for what each network is doing and there's a recent paper from Danny Bassets group at Penn which used network control theory to highlight this so they showed that that the default mode network is efficiently driving brain into the brain in two different states with little energy or input which we would call prediction right so it's the default mode network is guiding predictions which are then easily confirmed by the world and this is a very low cost very automatic very efficient way of of guiding action and creating experience the nodes in the the salience network drive the brain in two states that require more energy or input um so the the encoding of prediction error which deciding which prediction error to encode and which to ignore and in predictive coding lingo we would call this precision and they also showed that the core hubs facilitate neural integration across different network communities so allowing information in different networks to synchronize and create a stable representation and what I want to now suggest to you is something much more extreme I want to suggest something you much more speculative so so far I've showed you that these two core networks and their hubs contain regions that initiate changes in the brain's internal model of the world and that that model includes you your body and I showed you that some of the same brain regions that are associated with many psychological phenomena also establish a low stasis and represent its sensory consequences in effect I'm proposing to you that we should consider metabolism and energy regulation when we study any psychological phenomenon but now I'm gonna sort of that was on you know taking me out on the limb so I'm gonna crawl out on that limb even further and hope that it doesn't break and suggest to you that these two networks anchor the biology of meaning-making they allow you to know what sensory input means what caused the sensory input and what to do about that sensory input so put another way the brain's internal model its predictions can be understood as abstract ad hoc concepts conceptual concepts the brain is continually constructing concepts in a situated way and it's these concepts that are the concepts that I refer to earlier in the talk so in addition to shaping perception and driving action these concepts are the tools for establishing Alice thesis and regulating the energy needs of the body and the law for these hypotheses go something like this predictions are concepts that your brain generates in modern cognitive science what's a category a category or group of instances or events that are similar in some way what's a concept a concept is a group of representations that are similar in some way that are representing the category so what concept is a group of representations that are similar for some function or some purpose so when your brain is generating thousands of predictions at a time along with their prior probabilities for fitting the current situation when the brain is asking not what is this but what is this like it is in effect generating a concept it's generating a concept as a hypothesis or a tentative belief that is your brains best guess for what is about what is causing the sensory inputs that are about to occur so this concept that your brain is generating in an ad hoc situated way is a Bayesian filter for incoming sensory information and that once a prediction is sufficiently confirmed by the sensory input from the world then the sensations are categorized and explained so that you understand what caused them and you know what to do about them so part of meaning making is knowing how to act and predictably estimating the body's energy needs for that action and then this categorization is what guides your action and becomes your experience in your perception so the brain is basically categorizing all the time not the kind of explicit categorizing like oh just you know does is this a dog or a cat but categorizing in the sense of finding a set of past experiences that are um similar them to the current sensory array so when the brain generates a population of predictions using past experiences of emotion it's generating a Oshin concept as a hypothesis or attentive belief that is your brains best guess as to what is about to cause the sensory changes in the body and in the world right and so this prediction once it's confirmed has categorized and explained those sensations as emotion so you understand the emotion as the cause of your actions and as the physical changes in the cause of the physical changes in your body and this is why people believe that emotions create a central state that guides actions and experience emotions don't cause you to act emotions don't cause you to feel they are the explanation of what you do and how you feel now we can there's you know evidence I would say that's consistent with this hypothesis returning to the cortical gradients the lamination gradients in the cortical sheet so what's happening is well I just say that that the the lamination gradients allow us to have very specific computational hypotheses for how the brain is generating concepts so predictions originate in these in regions that have very large pyramidal cells with a lot of connections and the information cascades down to the more granular regions like primary visual cortex primary auditory cortex where the pyramidal neurons are much smaller and they have fewer connections so essentially what begins as a multimodal summary cascades into more detail and particularized representations as the information cascades out to primary sensory regions and prediction error works in the other direction right so goes from more granular regions to laughs from smaller neurons to bigger neurons with fewer connections to more connection so essentially what you're doing what you're seeing here is information is going from primary sensory regions which is very detailed being compressed and reduced in dimensionality until it hits the a granular regions where you have basically multimodal summaries or what sometimes what scientists call abstractions so when information flows from limbic regions out to the primary sensory regions you have concept generation multimodal summaries cascading to sensory and motor regions becoming progressively more particularized and learning all learning is basically concept learning where there's an integration across sensory domains and progressive dimensionality reduction across the cortical she'd now I could show you more information about the specific how this works specifically in the default mode Network and in the salience network but there isn't time for that today so I'm just going to wrap up and suggest to you that my my the summary of my suggestions here is that emotions are not your reactions to the world that cause action and experience they're your constructions of the world or more precisely they're your brains understanding of what is going on inside your own body in relation to what is happening in the world as the brain is running its internal model of your body in the world it's maintaining all of stasis and it's predicting what actions are necessary in the next moment to maintain Alice stasis and as a consequence it's simulating the sensory consequences creating not just your emotions but also your perceptions and your thoughts and so emotions that seem to happen to you are actually made by you and the emotion concepts that your brain can make the size and variety of your emotion vocabulary allows your brain to have a larger and more flexible repertoire of emotions that it can make and perceive in others this is what I call emotional granularity and it is one aspect of emotional intelligence and this is something that I discuss in my book and its relevance for for coping and for mental health and so on and so forth and where does the not this emotion knowledge come from so that the brain is equipped to make emotion concepts and I would suggest that it comes from the environment that we create for infants right that we create the environment that allows an infant brain to bootstrap emotion knowledge into its own wiring an infant brain is not a miniature adult brain it's a brain that's waiting for a set of wiring instructions from the world so that it knows how to wire itself to its physical and its social surroundings and part of that wiring is guided by that words that we speak the mental state words that we speak to the infant this is also how culture becomes embraer brain is basically a culture it's basically an artifact of the culture that you grew up in and that socialization is allows basically a brain to incorporate into its own wiring or bootstrap into its own wiring the emotion knowledge that it then uses to later to generate emotion knowledge I'm gonna skip this last part and basically end by thanking my wonderful lab whose very hard work that I just presented to you thanking the funding agencies that supported this work and thanking you for your attention\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.words.str.cat(sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
